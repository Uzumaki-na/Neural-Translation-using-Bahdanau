{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C24JKO7LxP3O"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf### models\n",
        "import numpy as np### math computations\n",
        "import matplotlib.pyplot as plt### plotting bar chart\n",
        "import sklearn### machine learning library\n",
        "import cv2## image processing\n",
        "from sklearn.metrics import confusion_matrix, roc_curve### metrics\n",
        "import seaborn as sns### visualizations\n",
        "import datetime\n",
        "import pathlib\n",
        "import io\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import time\n",
        "from numpy import random\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.layers import (Dense,Flatten,SimpleRNN,InputLayer,Conv1D,Bidirectional,GRU,LSTM,BatchNormalization,Dropout,Input, Embedding,TextVectorization)\n",
        "from tensorflow.keras.losses import BinaryCrossentropy,CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import Accuracy,TopKCategoricalAccuracy, CategoricalAccuracy, SparseCategoricalAccuracy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "from tensorboard.plugins import projector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKg0HdsrYA0S"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgU1Z8fcOSW_"
      },
      "source": [
        "## Data Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hwhov2uvDdo",
        "outputId": "fbe3ea6c-8c55-4be7-9013-363846458f7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-12-30 14:01:36--  https://www.manythings.org/anki/fra-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7943074 (7.6M) [application/zip]\n",
            "Saving to: ‘fra-eng.zip’\n",
            "\n",
            "fra-eng.zip         100%[===================>]   7.57M  19.5MB/s    in 0.4s    \n",
            "\n",
            "2024-12-30 14:01:37 (19.5 MB/s) - ‘fra-eng.zip’ saved [7943074/7943074]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.manythings.org/anki/fra-eng.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-ufBPwn8_ax",
        "outputId": "c9f3751d-0ae3-41c4-bdc8-2dab5460c9a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/fra-eng.zip\n",
            "  inflating: /content/dataset/_about.txt  \n",
            "  inflating: /content/dataset/fra.txt  \n"
          ]
        }
      ],
      "source": [
        "!unzip \"/content/fra-eng.zip\" -d \"/content/dataset/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBHsJDpiYDs7"
      },
      "source": [
        "## Kaggle Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Lako-uhxy-n",
        "outputId": "21b5a375-dc00-4119-f0ef-fc3b4e86190b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n",
            "Dataset URL: https://www.kaggle.com/datasets/dhruvildave/en-fr-translation-dataset\n",
            "License(s): ODbL-1.0\n",
            "Downloading en-fr-translation-dataset.zip to /content\n",
            " 99% 2.52G/2.54G [00:31<00:00, 105MB/s]\n",
            "100% 2.54G/2.54G [00:31<00:00, 86.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d dhruvildave/en-fr-translation-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B44hfX_vxzA-",
        "outputId": "f3668cd1-255d-4e6d-ddb7-79638f7bd3e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/en-fr-translation-dataset.zip\n",
            "  inflating: /content/dataset/en-fr.csv  \n"
          ]
        }
      ],
      "source": [
        "!unzip \"/content/en-fr-translation-dataset.zip\" -d \"/content/dataset/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXcOEWp2L7U9"
      },
      "outputs": [],
      "source": [
        "dataset = tf.data.experimental.CsvDataset(\n",
        "  \"/content/dataset/en-fr.csv\",\n",
        "  [\n",
        "    tf.string,\n",
        "    tf.string\n",
        "  ],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omyb2Dq_YHbT"
      },
      "source": [
        "## Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywC7WnoIJeXl"
      },
      "outputs": [],
      "source": [
        "text_dataset=tf.data.TextLineDataset(\"/content/dataset/fra.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlcJxz6cJeb_"
      },
      "outputs": [],
      "source": [
        "VOCAB_SIZE=20000\n",
        "ENGLISH_SEQUENCE_LENGTH=64\n",
        "FRENCH_SEQUENCE_LENGTH=64\n",
        "EMBEDDING_DIM=300\n",
        "BATCH_SIZE=64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TePer9o-JeeR"
      },
      "outputs": [],
      "source": [
        "english_vectorize_layer=TextVectorization(\n",
        "    standardize='lower_and_strip_punctuation',\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=ENGLISH_SEQUENCE_LENGTH\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unGn0zqEJegg"
      },
      "outputs": [],
      "source": [
        "french_vectorize_layer=TextVectorization(\n",
        "    standardize='lower_and_strip_punctuation',\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=FRENCH_SEQUENCE_LENGTH\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNK3uewuQTjY"
      },
      "outputs": [],
      "source": [
        "def selector(input_text):\n",
        "  split_text=tf.strings.split(input_text,'\\t')\n",
        "  return {'input_1':split_text[0:1],'input_2':'starttoken '+split_text[1:2]},split_text[1:2]+' endtoken'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZDH8xn7Q12e"
      },
      "outputs": [],
      "source": [
        "split_dataset=text_dataset.map(selector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fcSDED_2c-z"
      },
      "outputs": [],
      "source": [
        "def separator(input_text):\n",
        "  split_text=tf.strings.split(input_text,'\\t')\n",
        "  return split_text[0:1],'starttoken '+split_text[1:2]+' endtoken'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktN95hiN2pgU"
      },
      "outputs": [],
      "source": [
        "init_dataset=text_dataset.map(separator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQkSkpd1tils",
        "outputId": "d6236f77-5268-462e-9d69-e79cef8c9d8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken Va !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Va ! endtoken'], dtype=object)>)\n",
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken Marche.'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Marche. endtoken'], dtype=object)>)\n",
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken En route !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'En route ! endtoken'], dtype=object)>)\n"
          ]
        }
      ],
      "source": [
        "for i in split_dataset.take(3):\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_usEDYiOJeil"
      },
      "outputs": [],
      "source": [
        "english_training_data=init_dataset.map(lambda x,y:x)### input x,y and output x\n",
        "english_vectorize_layer.adapt(english_training_data)#### adapt the vectorize_layer to the training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dl7pxJprJek2"
      },
      "outputs": [],
      "source": [
        "french_training_data=init_dataset.map(lambda x,y:y)### input x,y,z and output y\n",
        "french_vectorize_layer.adapt(french_training_data)#### adapt the vectorize_layer to the training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yVIMxvTJemt"
      },
      "outputs": [],
      "source": [
        "def vectorizer(inputs,output):\n",
        "  return {'input_1':english_vectorize_layer(inputs['input_1']),\n",
        "          'input_2':french_vectorize_layer(inputs['input_2'])},french_vectorize_layer(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "op5UqhS14HHz",
        "outputId": "4cee43a1-6495-46c3-a587-c53c34142fcf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_MapDataset element_spec=({'input_1': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'input_2': TensorSpec(shape=(None,), dtype=tf.string, name=None)}, TensorSpec(shape=(None,), dtype=tf.string, name=None))>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wI9-GPpVJepF"
      },
      "outputs": [],
      "source": [
        "dataset=split_dataset.map(vectorizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_6Xtks8wPk5",
        "outputId": "2edbadf7-acb8-4daa-9d54-a2496b169c10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken Va !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Va ! endtoken'], dtype=object)>)\n",
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken Marche.'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Marche. endtoken'], dtype=object)>)\n",
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken En route !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'En route ! endtoken'], dtype=object)>)\n"
          ]
        }
      ],
      "source": [
        "for i in split_dataset.take(3):\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FM9aenklufpC",
        "outputId": "e29c380d-2ea4-4493-b38b-037ea2490397"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "({'input_1': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[45,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])>, 'input_2': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[  2, 104,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>}, <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[104,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>)\n"
          ]
        }
      ],
      "source": [
        "for i in dataset.take(1):\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOpSsko7TiKd",
        "outputId": "881d43e4-d22a-438e-a3f6-c306b67fedd8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_MapDataset element_spec=({'input_1': TensorSpec(shape=(None, None), dtype=tf.int64, name=None), 'input_2': TensorSpec(shape=(None, None), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, None), dtype=tf.int64, name=None))>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WE0s6p9TiM9"
      },
      "outputs": [],
      "source": [
        "dataset=dataset.shuffle(2048).unbatch().batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTkF_Qu54QB5",
        "outputId": "341ed2a7-6108-4313-b647-2686b678b8d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=({'input_1': TensorSpec(shape=(None, None), dtype=tf.int64, name=None), 'input_2': TensorSpec(shape=(None, None), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, None), dtype=tf.int64, name=None))>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5JXDdrNtwRj"
      },
      "outputs": [],
      "source": [
        "NUM_BATCHES=int(200000/BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQvg18V5TiO7"
      },
      "outputs": [],
      "source": [
        "train_dataset=dataset.take(int(0.9*NUM_BATCHES))\n",
        "val_dataset=dataset.skip(int(0.9*NUM_BATCHES))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfCmn1DzTiRp",
        "outputId": "39f48186-9082-4fe3-8608-f9d92815d2d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_TakeDataset element_spec=({'input_1': TensorSpec(shape=(None, None), dtype=tf.int64, name=None), 'input_2': TensorSpec(shape=(None, None), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, None), dtype=tf.int64, name=None))>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBVM2EB0Xh97"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hABAiQjTsf5p"
      },
      "source": [
        "## Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7LmYWQ2cwaq"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self,vocab_size,embedding_dim,units):\n",
        "    super(Encoder,self).__init__()\n",
        "    self.embedding_dim=embedding_dim\n",
        "    self.vocab_size=vocab_size\n",
        "    self.units=units\n",
        "\n",
        "  def build(self,input_shape):\n",
        "    self.embedding=Embedding(self.vocab_size,self.embedding_dim)\n",
        "    self.lstm=LSTM(self.units,return_sequences=True)\n",
        "\n",
        "  def call(self,x):\n",
        "    x=self.embedding(x)\n",
        "    output=self.lstm(x)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7ulQFtecwdU",
        "outputId": "56eab0e2-ad92-4e24-f758-1daf119674d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(128, 8, 256)\n"
          ]
        }
      ],
      "source": [
        "HIDDEN_UNITS=256\n",
        "EMBEDDING_DIM=256\n",
        "encoder=Encoder(VOCAB_SIZE,EMBEDDING_DIM,HIDDEN_UNITS)\n",
        "encoder_output=encoder(tf.zeros([128,8]))\n",
        "print(encoder_output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGJkopfjshmf"
      },
      "source": [
        "## Bahdanau Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qD-2QY-YcwgM"
      },
      "outputs": [],
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self,units):\n",
        "    super(BahdanauAttention,self).__init__()\n",
        "    self.units=units\n",
        "\n",
        "  def build(self,input_shape):\n",
        "    self.w_1=tf.keras.layers.Dense(self.units)\n",
        "    self.w_2=tf.keras.layers.Dense(self.units)\n",
        "    self.w=tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self,prev_dec_state,enc_states):\n",
        "    scores=self.w(\n",
        "        tf.nn.tanh(\n",
        "        self.w_1(tf.expand_dims(prev_dec_state,-2)) +\n",
        "        self.w_2(enc_states)))\n",
        "\n",
        "    attention_weights=tf.nn.softmax(scores,axis=1)\n",
        "    context_vector=attention_weights*enc_states\n",
        "    context_vector=tf.reduce_sum(context_vector,axis=1)\n",
        "    return context_vector,attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naL8ZNDscwme",
        "outputId": "eaf54d7d-88fe-4393-c8a4-78cf6b156b68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(128, 32)\n",
            "(128, 8, 1)\n"
          ]
        }
      ],
      "source": [
        "bahdanau_attention=BahdanauAttention(256)\n",
        "context_vector,attention_weights=bahdanau_attention(tf.zeros([128,32]),tf.zeros([128,8,32]))\n",
        "print(context_vector.shape)\n",
        "print(attention_weights.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETCM23b6sktH"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMwWra7_cwpc"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self,vocab_size,embedding_dim,dec_units,sequence_length):\n",
        "    super(Decoder,self).__init__()\n",
        "    self.embedding_dim=embedding_dim\n",
        "    self.vocab_size=vocab_size\n",
        "    self.dec_units=dec_units\n",
        "    self.sequence_length=sequence_length\n",
        "\n",
        "  def build(self,input_shape):\n",
        "    self.dense=Dense(self.vocab_size,activation=\"softmax\")\n",
        "    self.gru=GRU(\n",
        "        self.dec_units,return_sequences=True,return_state=True)\n",
        "    self.attention=BahdanauAttention(self.dec_units)\n",
        "    self.embedding=Embedding(self.vocab_size,self.embedding_dim)\n",
        "\n",
        "  def call(self,x,hidden,shifted_target):\n",
        "    outputs=[]\n",
        "    context_vectors=[]\n",
        "    attention_weightss=[]\n",
        "    shifted_target=self.embedding(shifted_target)\n",
        "\n",
        "    for t in range(0,self.sequence_length):\n",
        "      context_vector,attention_weights=self.attention(hidden,x)\n",
        "      dec_input=context_vector+shifted_target[:,t]\n",
        "      output,hidden=self.gru(tf.expand_dims(dec_input,1))\n",
        "      outputs.append(output[:,0])\n",
        "\n",
        "    outputs=tf.convert_to_tensor(outputs)\n",
        "    outputs=tf.transpose(outputs, perm=[1,0,2])\n",
        "\n",
        "    outputs=self.dense(outputs)\n",
        "    return outputs,attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qp9SVaGRcwr-",
        "outputId": "e5f00528-1506-4a22-bd05-d8bc7590445c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(128, 64, 20000)\n",
            "(128, 8, 1)\n"
          ]
        }
      ],
      "source": [
        "decoder=Decoder(VOCAB_SIZE,EMBEDDING_DIM,HIDDEN_UNITS,FRENCH_SEQUENCE_LENGTH)\n",
        "outputs,attention_weights=decoder(encoder_output,tf.zeros([128,HIDDEN_UNITS]),tf.zeros([128,64]))\n",
        "print(outputs.shape)\n",
        "print(attention_weights.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "Q3O-AVFzcwup",
        "outputId": "c52020bd-e0d7-4598-de58-8efbb7934060"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Encoder</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,645,312</span> │ input_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Decoder</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20000</span>),    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">10,786,593</span> │ encoder_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)]         │                │ input_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ encoder_1 (\u001b[38;5;33mEncoder\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │      \u001b[38;5;34m5,645,312\u001b[0m │ input_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_1 (\u001b[38;5;33mDecoder\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m20000\u001b[0m),    │     \u001b[38;5;34m10,786,593\u001b[0m │ encoder_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m)]         │                │ input_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,431,905</span> (62.68 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,431,905\u001b[0m (62.68 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,431,905</span> (62.68 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,431,905\u001b[0m (62.68 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "### ENCODER\n",
        "input = Input(shape=(ENGLISH_SEQUENCE_LENGTH,), dtype=\"int64\", name=\"input_1\")\n",
        "encoder=Encoder(VOCAB_SIZE,EMBEDDING_DIM,HIDDEN_UNITS)\n",
        "encoder_output=encoder(input)\n",
        "\n",
        "### DECODER\n",
        "shifted_target=Input(shape=(FRENCH_SEQUENCE_LENGTH,), dtype=\"int64\", name=\"input_2\")\n",
        "decoder=Decoder(VOCAB_SIZE,EMBEDDING_DIM,HIDDEN_UNITS,FRENCH_SEQUENCE_LENGTH)\n",
        "decoder_output,attention_weightss=decoder(encoder_output,tf.zeros([1,HIDDEN_UNITS]),shifted_target)\n",
        "\n",
        "### OUTPUT\n",
        "bahdanau=Model([input,shifted_target],decoder_output)\n",
        "bahdanau.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIzOQNEucwyG"
      },
      "outputs": [],
      "source": [
        "class BLEU(tf.keras.metrics.Metric):\n",
        "    def __init__(self,name='bleu_score'):\n",
        "        super(BLEU,self).__init__()\n",
        "        self.bleu_score=0\n",
        "\n",
        "    def update_state(self,y_true,y_pred,sample_weight=None):\n",
        "      y_pred=tf.argmax(y_pred,-1)\n",
        "      self.bleu_score=0\n",
        "      for i,j in zip(y_pred,y_true):\n",
        "        tf.autograph.experimental.set_loop_options()\n",
        "\n",
        "        total_words=tf.math.count_nonzero(i)\n",
        "        total_matches=0\n",
        "        for word in i:\n",
        "          if word==0:\n",
        "            break\n",
        "          for q in range(len(j)):\n",
        "            if j[q]==0:\n",
        "              break\n",
        "            if word==j[q]:\n",
        "              total_matches+=1\n",
        "              j=tf.boolean_mask(j,[False if y==q else True for y in range(len(j))])\n",
        "              break\n",
        "\n",
        "        self.bleu_score+=total_matches/total_words\n",
        "\n",
        "    def result(self):\n",
        "        return self.bleu_score/BATCH_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oe0WGqZmcxGp"
      },
      "outputs": [],
      "source": [
        "bahdanau.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    optimizer=tf.keras.optimizers.Adam(5e-4),\n",
        "    metrics=[BLEU()],\n",
        "    run_eagerly=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tai1ZEi1cxJn"
      },
      "outputs": [],
      "source": [
        "checkpoint_filepath = '/content/drive/MyDrive/nlp/translation/bahdanau_attention_1.keras'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "5VUmxwl5e8pl",
        "outputId": "fdaa2dcc-cbdf-4e25-a916-7bc46a38faea"
      },
      "outputs": [],
      "source": [
        "history=bahdanau.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=3,)\n",
        "    #callbacks=[model_checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "5c5A7_pudzP8",
        "outputId": "719ed4aa-a341-4826-e530-d422c7ef88a6"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model_loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsF_wos17EOC"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "\n",
        "plt.title('model_accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z67BesEQ7EQC"
      },
      "outputs": [],
      "source": [
        "bahdanau.evaluate(val_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4i1ajAymaDoF"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5vMnTM62Cx_"
      },
      "outputs": [],
      "source": [
        "index_to_word={x:y for x, y in zip(range(len(french_vectorize_layer.get_vocabulary())),\n",
        "                                   french_vectorize_layer.get_vocabulary())}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HiWzshkMKfQg"
      },
      "outputs": [],
      "source": [
        "def translator(english_sentence):\n",
        "  tokenized_english_sentence=english_vectorize_layer([english_sentence])\n",
        "  shifted_target='starttoken'\n",
        "\n",
        "  for i in range(FRENCH_SEQUENCE_LENGTH):\n",
        "    tokenized_shifted_target=french_vectorize_layer([shifted_target])\n",
        "    output=bahdanau.predict([tokenized_english_sentence,tokenized_shifted_target])\n",
        "    french_word_index=tf.argmax(output,axis=-1)[0][i].numpy()\n",
        "    current_word=index_to_word[french_word_index]\n",
        "    if current_word=='endtoken':\n",
        "      break\n",
        "    shifted_target+=' '+current_word\n",
        "  return shifted_target[11:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "0RYy2vtxKfS7",
        "outputId": "75e6711f-f634-43b1-dfd2-a52ec3c7a8c5"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'translator' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-ac7e0bc43dea>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtranslator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'What makes you think that is not true?'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'translator' is not defined"
          ]
        }
      ],
      "source": [
        "translator('What makes you think that is not true?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymusGWncm6sr"
      },
      "outputs": [],
      "source": [
        "translator('Have you ever watched a soccer under the rain?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6y34Nhv79U_"
      },
      "outputs": [],
      "source": [
        "translator('Great trees do not grow with ease, the stronger the winds, the stronger the trees')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDfIbnVL79XE"
      },
      "outputs": [],
      "source": [
        "translator('Everyone should water his or her tomato plants')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1BQFbrdKfVZ"
      },
      "outputs": [],
      "source": [
        "word_to_index={y:x for x, y in zip(range(len(french_vectorize_layer.get_vocabulary())),\n",
        "                                   french_vectorize_layer.get_vocabulary())}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "RBHsJDpiYDs7"
      ],
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
